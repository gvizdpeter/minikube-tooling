injector:
  # True if you want to enable vault agent injection.
  enabled: false

server:
  # Supported log levels include: trace, debug, info, warn, error
  logLevel: "warn"

  # Configure the logging format for the Vault server.
  # Supported log formats include: standard, json
  logFormat: "json"

  image:
    repository: "hashicorp/vault"
    tag: "1.8.3"

  extraSecretEnvironmentVars:
    - envName: VAULT_UNSEAL_KEY_BASE64
      secretName: ${vault_unseal_key_base64_secret_name}
      secretKey: ${vault_unseal_key_base64_secret_key}
    - envName: VAULT_ADMIN_USERNAME
      secretName: ${vault_admin_secret_name}
      secretKey: ${vault_admin_username_secret_key}
    - envName: VAULT_ADMIN_PASSWORD
      secretName: ${vault_admin_secret_name}
      secretKey: ${vault_admin_password_secret_key}

  extraEnvironmentVars:
    VAULT_ADMIN_POLICY_HCL: /tmp/vault-admin-policy.hcl

  volumes:
    - name: vault-init-configmap
      configMap:
        name: ${vault_init_configmap_name}

  volumeMounts:
    - mountPath: /tmp/vault-init-script.sh.ro
      subPath: ${vault_init_script_name}
      name: vault-init-configmap

    - mountPath: /tmp/vault-admin-policy.hcl
      subPath: ${vault_admin_policy_name}
      name: vault-init-configmap

  postStart:
    - "/bin/sh"
    - "-c"
    - "sleep 30 && cp /tmp/vault-init-script.sh.ro /tmp/vault-init-script.sh && chmod a+x /tmp/vault-init-script.sh && /tmp/vault-init-script.sh &> /proc/1/fd/1"

  resources:
    requests:
      memory: 256Mi
      cpu: 250m
    limits:
      memory: 256Mi
      cpu: 250m

  # Affinity Settings
  # Commenting out or setting as empty the affinity variable, will allow
  # deployment to single node services such as Minikube
  # This should be either a multi-line string or YAML matching the PodSpec's affinity field.
  affinity: ""

  # Extra labels to attach to the server pods
  # This should be a YAML map of the labels to apply to the server pods
  extraLabels:
    app: vault

  # This configures the Vault Statefulset to create a PVC for data
  # storage when using the file or raft backend storage engines.
  # See https://www.vaultproject.io/docs/configuration/storage/index.html to know more
  dataStorage:
    enabled: true
    # Size of the PVC created
    size: 1Gi
    # Location where the PVC will be mounted.
    mountPath: "/vault/data"
    # Name of the storage class to use.  If null it will use the
    # configured default Storage Class.
    storageClass: ${storage_class_name}
    # Access Mode of the storage device being used for the PVC
    accessMode: ReadWriteOnce

  # This configures the Vault Statefulset to create a PVC for audit
  # logs.  Once Vault is deployed, initialized and unseal, Vault must
  # be configured to use this for audit logs.  This will be mounted to
  # /vault/audit
  # See https://www.vaultproject.io/docs/audit/index.html to know more
  auditStorage:
    enabled: true
    # Size of the PVC created
    size: 1Gi
    # Location where the PVC will be mounted.
    mountPath: "/vault/audit"
    # Name of the storage class to use.  If null it will use the
    # configured default Storage Class.
    storageClass: ${storage_class_name}
    # Access Mode of the storage device being used for the PVC
    accessMode: ReadWriteOnce

  # Run Vault in "standalone" mode. This is the default mode that will deploy if
  # no arguments are given to helm. This requires a PVC for data storage to use
  # the "file" backend.  This mode is not highly available and should not be scaled
  # past a single replica.
  standalone:
    enabled: true

    # config is a raw string of default configuration when using a Stateful
    # deployment. Default is to use a PersistentVolumeClaim mounted at /vault/data
    # and store data there. This is only used when using a Replica count of 1, and
    # using a stateful set. This should be HCL.

    # Note: Configuration files are stored in ConfigMaps so sensitive data
    # such as passwords should be either mounted through extraSecretEnvironmentVars
    # or through a Kube secret.  For more information see:
    # https://www.vaultproject.io/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
    config: |
      ui = true

      listener "tcp" {
        tls_disable = 1
        address = "[::]:8200"
        cluster_address = "[::]:8201"
      }
      storage "file" {
        path = "/vault/data"
      }

  # Enables a headless service to be used by the Vault Statefulset
  service:
    enabled: true
    # clusterIP controls whether a Cluster IP address is attached to the
    # Vault service within Kubernetes.  By default the Vault service will
    # be given a Cluster IP address, set to None to disable.  When disabled
    # Kubernetes will create a "headless" service.  Headless services can be
    # used to communicate with pods directly through DNS instead of a round robin
    # load balancer.
    # clusterIP: None

    # Configures the service type for the main Vault service.  Can be ClusterIP
    # or NodePort.
    type: ClusterIP

    # If type is set to "NodePort", a specific nodePort value can be configured,
    # will be random if left blank.
    #nodePort: 30000

    # Port on which Vault server is listening
    port: 8200
    # Target port to which the service should be mapped to
    targetPort: 8200
    # Extra annotations for the service definition. This can either be YAML or a
    # YAML-formatted multi-line templated string map of the annotations to apply
    # to the service.
    annotations: {}

  # Definition of the serviceAccount used to run Vault.
  # These options are also used when using an external Vault server to validate
  # Kubernetes tokens.
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: "vault-service-account"

# Vault UI
ui:
  # True if you want to create a Service entry for the Vault UI.
  #
  # serviceType can be used to control the type of service created. For
  # example, setting this to "LoadBalancer" will create an external load
  # balancer (for supported K8S installations) to access the UI.
  enabled: true
